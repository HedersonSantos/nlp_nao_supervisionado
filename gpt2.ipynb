{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKNK6Ml/9ib14r6tVVilU8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HedersonSantos/nlp_nao_supervisionado/blob/main/gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fULk4eHJyrr",
        "outputId": "4a6b0621-5325-4904-f679-ff41dc2e15b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "#!pip install torch transformers\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "7VV4hysPNLwK"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textos = ['''Correios Log+\n",
        "O serviço Correios Log+ suporta operações logísticas completas, com armazenagem, atendimento de pedidos e integração aos demais serviços de entrega e logística reversa dos Correios.\n",
        "Também chamado de fulfillment, é destinado às empresas que atuam na venda de produtos para os mercados nacional e internacional, que poderão contar com um único operador logístico capaz de fornecer todo suporte necessário e reconhecido pela sua liderança no mercado de entregas.\n",
        "Empresas que atuam (ou desejam atuar) no comércio eletrônico por meio de site próprio ou marketplaces podem contratar o serviço Correios Log+.\n",
        "É por meio da formalização de parceria com os Correios, através da celebração do contrato comercial ou inclusão do serviço no contrato já existente, que os clientes poderão iniciar suas operações no Correios Log.\n",
        "A contratação dos Correios poderá ser feita na internet, por meio do Correios Fácil, ou diretamente com os Assistentes Comerciais.\n",
        "Os Correios assumem as etapas mais onerosas do processo logístico no comércio eletrônico, que é a armazenagem e o manuseio, bem como a logística internacional, quando for o caso. Isso permite que as empresas ganhem celeridade no processo operacional ao transferir estas responsabilidades para um único operador logístico.\n",
        "Após incluir o serviço no contrato, analise quais são as localidades que melhor atendem suas necessidades.\n",
        "Para que o cliente possa armazenar os produtos nos Centros dos Correios, a legislação brasileira requer que o cliente crie uma filial (fiscal) em cada estado onde desejar realizar operação.\n",
        "Cidades onde o serviço será prestado:\n",
        "Brasília DF:\n",
        "Cajamar SP:\n",
        "Rio de Janeiro RJ:\n",
        "Contagem MG:\n",
        "Curitiba PR:\n",
        "Florianópolis SC:\n",
        "Fortaleza CE:\n",
        "Manaus AM:\n",
        "Porto Alegre RS:\n",
        "Recife PE:\n",
        "Salvador BA:\n",
        "Goiânia - GO;\n",
        "Ribeirão Preto - SP\n",
        "Para a execução do serviço Correios Log+, é preciso utilizar um sistema de ERP integrado aos Correios por meio das APIs do Correios Log+.\n",
        "Com a integração dos sistemas tecnológicos, os Correios recebem os pedidos, separam os produtos disponíveis em estoque, embalam e preparam para o envio, com impressão de etiquetas de postagens e documentos fiscais necessários conforme legislação vigente. ''',\n",
        "'''Emissão CPF\n",
        "O que é?\n",
        "É o serviço que permite ao cidadão solicitar CPF, alterar dados cadastrais e regularizar a situação do CPF suspenso nas agências dos Correios do país.\n",
        "Quem pode utilizar este serviço?\n",
        "Pessoas físicas e órgãos públicos com contrato a faturar com os Correios para atendimento aos cidadãos que não têm condições de pagar pelo serviço.\n",
        "Como funciona?\n",
        "Para brasileiros com idade dos 18 aos 69 anos: título de eleitor, alistamento eleitoral, protocolo de inscrição ou certidão da Justiça Eleitoral atestando a não obrigatoriedade do alistamento eleitoral), solicitar o serviço e pagar a taxa.\n",
        "Você sai da agência com o novo CPF e com as solicitações referentes ao serviço atendidas no mesmo instante.\n",
        "E para o menor de 16 anos, tutelado, curatelado ou outra pessoa sujeita à guarda judicial?\n",
        "A solicitação do CPF deverá ser feita pelo representante legal, que pode ser pai ou mãe, tutores, curadores ou responsáveis pela guarda judicial; Carteira de identidade ou certidão de nascimento que comprove a naturalidade, a filiação e a data de nascimento do menor, tutelado ou curatelado; e documentos que atestem a tutela, curatela ou responsabilidade pela guarda de incapaz ou interdito.\n",
        "E quem tiver entre 16 e 18 anos incompletos?\n",
        "São assistidos legalmente, podendo assinar por seus atos ou não. Há uma Instrução Normativa da Receita Federal que estabelece que nesses casos pai ou mãe poderão assinar pela solicitação do CPF.\n",
        "Se for estrangeiro?\n",
        "Poderá ser aceito como documento de identificação o que é admitido no seu país de origem. Também poderão ser apresentados o RNE (Registro Nacional de Estrangeiro), o passaporte, ou o protocolo do RNE acompanhado da tela de consulta impressa do SINCRE - Sistema Nacional de Estrangeiros, constando os dados cadastrais. Não é obrigatória a comprovação de filiação de estrangeiros.\n",
        "Veja o que fazer se for alterar ou regularizar os dados do CPF:\n",
        "É possível solicitar gratuitamente a correção dos dados do CPF em até 60 dias. Vá até uma agência dos Correios dentro desse prazo e formalize a alteração;\n",
        "• Se você casou e quer alterar seu nome, deve apresentar a certidão de casamento, mas se for fazer a comprovação da data de nascimento basta apresentar a carteira de identidade;\n",
        "• Para solicitar alteração de endereço não é preciso apresentar comprovante de residência;\n",
        "• Os brasileiros ou estrangeiros que moram em outro país ou aqueles residentes no Brasil que estejam em viagem ao exterior podem solicitar alteração de dados cadastrais;\n",
        "• Quem estiver com a situação cadastral \"pendente de regularização\" ou \"suspensa\" precisa fazer a regularização mesmo que não tenha sido obrigado a entregar a Declaração do Imposto de Renda nos últimos cinco anos.\n",
        "Quanto custa?\n",
        "R$7,00 (sete reais)''',\n",
        "'''Tipo de Atendimento:\n",
        "Conclusivo: é o atendimento realizado exclusivamente pelos Correios, sem a necessidade do cliente comparecer à unidade local da Secretaria Receita Federal do Brasil.\n",
        "Não conclusivo: é o atendimento realizado inicialmente nos Correios e concluído pela Secretaria Receita Federal do Brasil. Os clientes enquadrados em uma das situações específicas, relacionadas a seguir, receberão Atendimento Não Conclusivo:\n",
        "a) Pessoas com idade igual ou superior a 25 (vinte cinco) anos;\n",
        "b) Homônimo Perfeito;\n",
        "c) Nome mãe = \"mãe desconhecida\" ou em branco;\n",
        "d) Data nascimento não oficial: pessoa com data de nascimento inválida registrada na documentação oficial;\n",
        "e) Nome contribuinte inválido: pessoa registrada com apenas o prenome, sem sobrenome, com nome com mais de quinze partes, abreviado, com caracteres não válidos;\n",
        "f) Nome mãe inválido: pessoa registrada com nome da mãe com apenas o prenome, sem sobrenome, com nome com mais de quinze partes, abreviado, com caracteres não válidos;\n",
        "g) Título de Eleitor já utilizado por outro CPF;\n",
        "h) CPF não encontrado na base ou (para inclusão) não pertence à faixa MIA (Modelo de inscrição e Atualização);\n",
        "i) Título de Eleitor não informado, mas informado motivo de ausência;\n",
        "j) Município de naturalidade = 9707 e sem indicativo de estrangeiro na base CPF;\n",
        "k) CPF em situação cadastral cancelada ou nula;\n",
        "l) CPF de responsável legal inválido, não encontrado na base CPF ou na situação cancelada ou nula;\n",
        "m) Título de Eleitor diverge da base;\n",
        "n) Nome e/ou nascimento diverge com a base RFB;\n",
        "o) Nome da mãe não pode ser alterado (mãe desconhecida, em branco, divergente da base TSE) e/ou Sexo não pode ser alterado.\n",
        "Impeditivo: é aquele que apresenta alguma inconsistência no atendimento, não permitindo a finalização do atendimento. Os clientes enquadrados em uma das situações específicas, relacionadas a seguir, receberão Atendimento Impeditivo:\n",
        "a) Solicita o serviço de correção, mas a última operação no CPF não é da conveniada solicitante. (Essa situação irá ocorrer se uma pessoa solicitar um serviço (Inscrição ou Alteração) nos agentes conveniados Banco do Brasil - BB ou Caixa Econômica Federal - CEF e depois pedir a correção nos Correios;\n",
        "b) Solicita alteração, mas os dados informados estão iguais aos da base CPF;\n",
        "c) Solicita correção cadastral, mas os dados informados estão iguais aos da base\n",
        "CPF; d) Solicita regularização, mas o CPF já está regular;\n",
        "e) Solicita regularização, mas CPF consta como omisso de DIRPF. ''']"
      ],
      "metadata": {
        "id": "JJHcY3HWKgzq"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in textos:\n",
        "  print(len(t.split(' ')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juj6ygehQc26",
        "outputId": "224e3e82-0f15-41e1-fdb6-33c76f072e9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324\n",
            "425\n",
            "370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class textoDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # Definimos labels como input_ids, isso é necessário para Masked Language Modeling\n",
        "        item['labels'] = item['input_ids'].clone()\n",
        "        return item"
      ],
      "metadata": {
        "id": "1dYgkBJGNFWy"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "pTD4nzkkW3Mk"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização dos textos\n",
        "# Dataset e DataLoader\n",
        "dataset = textoDataset(textos, tokenizer)\n",
        "#train_loader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "dCftT4sFQwNq"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bin2WWanR8Mz",
        "outputId": "8dd531a7-a3fd-47ce-f358-9d5d10423f8c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    overwrite_output_dir=True,\n",
        "    output_dir='./gpt2_saida'\n",
        "\n",
        "\n",
        ")#prediction_loss_only=True\n",
        "#eval_strategy=\"epoch\","
      ],
      "metadata": {
        "id": "ZxWFSvyiP5jS"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "\n",
        ")\n",
        "#compute_metrics=compute_loss\n",
        "#eval_dataset=eval_dataset"
      ],
      "metadata": {
        "id": "-RRhjWY7RuPD"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "czhIProZTgNr",
        "outputId": "86920f88-1c9c-4710-b812-480ccd211b5e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-b0380bf3ca90>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=4.326728185017903, metrics={'train_runtime': 3.1686, 'train_samples_per_second': 2.84, 'train_steps_per_second': 0.947, 'total_flos': 4675698432000.0, 'train_loss': 4.326728185017903, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salve o modelo ajustado\n",
        "model.save_pretrained('./finetuned_gpt2')\n",
        "tokenizer.save_pretrained('./finetuned_gpt2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irHsA2BUcwI8",
        "outputId": "06e997ce-ea79-4a63-bb6b-c2c876b2fa61"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned_gpt2/tokenizer_config.json',\n",
              " './finetuned_gpt2/special_tokens_map.json',\n",
              " './finetuned_gpt2/vocab.json',\n",
              " './finetuned_gpt2/merges.txt',\n",
              " './finetuned_gpt2/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh finetuned_gpt2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCVgZ_PChWm5",
        "outputId": "12fbaf34-fcdb-4261-b22e-f76bc0e14b3d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 477M\n",
            "-rw-r--r-- 1 root root  907 Jun 15 20:55 config.json\n",
            "-rw-r--r-- 1 root root  119 Jun 15 20:55 generation_config.json\n",
            "-rw-r--r-- 1 root root 446K Jun 15 20:55 merges.txt\n",
            "-rw-r--r-- 1 root root 475M Jun 15 20:55 model.safetensors\n",
            "-rw-r--r-- 1 root root  470 Jun 15 20:55 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root  525 Jun 15 20:55 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root 976K Jun 15 20:55 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Carrega o modelo ajustado para geração de texto\n",
        "model_path = \"./finetuned_gpt2\"  # Atualize com o caminho correto\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path, truncation=True)\n",
        "# Define o token de padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Cria um pipeline para geração de texto\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Exemplo de uso do modelo ajustado\n",
        "prompt = \"Em português, what is postman?\"\n",
        "generated_text = generator(prompt, max_length=100, num_return_sequences=1)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MIH6VObY7Qt",
        "outputId": "c1eadcb1-8254-45bb-9059-cfb311d5b184"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Em português, what is postman?\\n\\nJárzej \"pjektic\" de Kralinjún: I am a postman. One day I will be at a bar with my friend Jóhannján \"járljevojó\". I will be in the car with some friends. After that I will come out of bed and sit down and eat my first sandwich.\\n\\nOn the other hand I will keep'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Este é um exemplo de texto em português que será tokenizado.\"\n",
        "inputs = tokenizer(texto, return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_CZyXTIqjTA",
        "outputId": "0145fefe-f163-4d2e-8d38-bb8d3394d037"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   36,  4169, 38251, 23781, 21433,    78,   390,  2420,    78,   795,\n",
              "          2493, 45284, 25792,    82,  8358,  1055,  6557, 11241,   528,  4533,\n",
              "            13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ]
}